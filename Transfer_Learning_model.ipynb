{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.regularizers import l2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_and_log_training_time(modelname, start_time, end_time):\n",
    "    training_duration = end_time - start_time\n",
    "    hours, rem = divmod(training_duration, 3600)\n",
    "    minutes, seconds = divmod(rem, 60)\n",
    "    \n",
    "    model_dir = modelname\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.makedirs(model_dir)\n",
    "    \n",
    "    filepath = os.path.join(model_dir, \"trainingtime.txt\")\n",
    "    with open(filepath, \"w\") as f:\n",
    "        f.write(f\"Training took {int(hours):02d}:{int(minutes):02d}:{seconds:02f} (hh:mm:ss).\")\n",
    "\n",
    "def save_model_config_with_optimizer(model, modelname):\n",
    "    model_dir = modelname\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.makedirs(model_dir)\n",
    "    \n",
    "    filepath = os.path.join(model_dir, \"model_config.txt\")\n",
    "    with open(filepath, 'w') as f:\n",
    "        for layer in model.layers:\n",
    "            f.write(f\"Layer: {layer.name}\\n\")\n",
    "            f.write(f\"Config: {layer.get_config()}\\n\\n\")\n",
    "        \n",
    "        optimizer_config = model.optimizer.get_config()\n",
    "        f.write(\"Optimizer Config:\\n\")\n",
    "        f.write(str(optimizer_config))\n",
    "\n",
    "def save_model(model, modelname):\n",
    "    model_dir = modelname\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.makedirs(model_dir)\n",
    "    \n",
    "    model_path = os.path.join(model_dir, modelname + \".keras\")\n",
    "    model.save(model_path)\n",
    "\n",
    "def save_performance_metrics(history, modelname):\n",
    "    model_dir = modelname\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.makedirs(model_dir)\n",
    "    \n",
    "    filepath = os.path.join(model_dir, 'performance_metrics.csv')\n",
    "    pd.DataFrame(history.history).to_csv(filepath)\n",
    "\n",
    "def plot_loss_and_metric(history, metric_name='accuracy', model_name='model'):\n",
    "    model_dir = model_name\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.makedirs(model_dir)\n",
    "    \n",
    "    # First plot: Training & validation loss\n",
    "    fig, ax = plt.subplots(figsize=(14, 6))\n",
    "    ax.plot(history.history['loss'], label='Train Loss')\n",
    "    ax.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    ax.set_title('Model Loss')\n",
    "    ax.set_ylabel('Loss')\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.legend(loc='upper right')\n",
    "    ax.grid(True)\n",
    "    loss_plot_filename = os.path.join(model_dir, f'{model_name}_loss_plot.jpg')\n",
    "    fig.savefig(loss_plot_filename)\n",
    "    print(f\"Loss plot saved as: {loss_plot_filename}\")\n",
    "    plt.close(fig)\n",
    "    \n",
    "    # Second plot: Training & validation metric\n",
    "    fig, ax = plt.subplots(figsize=(14, 6))\n",
    "    ax.plot(history.history[metric_name], label=f'Train {metric_name.capitalize()}')\n",
    "    ax.plot(history.history[f'val_{metric_name}'], label=f'Validation {metric_name.capitalize()}')\n",
    "    ax.set_title(f'Model {metric_name.capitalize()}')\n",
    "    ax.set_ylabel(metric_name.capitalize())\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.legend(loc='upper left')\n",
    "    ax.grid(True)\n",
    "    metric_plot_filename = os.path.join(model_dir, f'{model_name}_{metric_name}_plot.jpg')\n",
    "    fig.savefig(metric_plot_filename)\n",
    "    print(f\"Metric plot saved as: {metric_plot_filename}\")\n",
    "    plt.close(fig)\n",
    "\n",
    "def save_model_and_config_and_metrics(model, history, modelname = \"model\"):\n",
    "    save_model_config_with_optimizer(model, modelname = modelname)\n",
    "    save_model(model, modelname = modelname)\n",
    "    save_performance_metrics(history, modelname = modelname)\n",
    "    plot_loss_and_metric(history, metric_name='mae', model_name= modelname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning RESNET50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"C:\\Users\\busjo\\Documents\\JADS\\Semester 2\\Deep Learning\\Project\\Part1_Processed_RGB.pkl\"\n",
    "# Open the pickle file in binary mode\n",
    "with open(path, 'rb') as file:\n",
    "    # Load the content of the file into a variable\n",
    "    RGB_data = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_RGB_data = RGB_data.sample(n=1000, random_state=2001)\n",
    "y = sampled_RGB_data['Age'].values\n",
    "X = sampled_RGB_data['Image'].values\n",
    "X = np.stack(X)  # This should result in a numpy array of shape (num_samples, 256, 256, 3)\n",
    "\n",
    "# Function to resize and normalize images\n",
    "def preprocess_images(images):\n",
    "    \"\"\"Resize images to 224x224 and normalize them.\"\"\"\n",
    "    images = tf.image.resize(images, [224, 224], method='bilinear')\n",
    "    # Normalize images to [-1, 1] if using a model pretrained on ImageNet\n",
    "    images = (images / 127.5) - 1\n",
    "    return images.numpy()  # Convert back to numpy array\n",
    "\n",
    "# Apply preprocessing to all images\n",
    "X = preprocess_images(X)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 2s/step - loss: 1163.8221 - mae: 26.5446 - val_loss: 559.7067 - val_mae: 19.9884\n",
      "Epoch 2/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 1s/step - loss: 679.8377 - mae: 22.5845 - val_loss: 620.6669 - val_mae: 22.0794\n",
      "Epoch 3/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 1s/step - loss: 650.6486 - mae: 21.9804 - val_loss: 578.5123 - val_mae: 20.9579\n",
      "Epoch 4/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1s/step - loss: 630.3478 - mae: 21.2781 - val_loss: 587.5080 - val_mae: 21.2427\n",
      "Epoch 5/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1s/step - loss: 633.4879 - mae: 21.7047 - val_loss: 588.7366 - val_mae: 21.2793\n",
      "Epoch 6/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 1s/step - loss: 614.9753 - mae: 21.2268 - val_loss: 591.9930 - val_mae: 21.3728\n",
      "Epoch 7/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 1s/step - loss: 630.8163 - mae: 21.4023 - val_loss: 586.5230 - val_mae: 21.2131\n",
      "Epoch 8/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 2s/step - loss: 629.1222 - mae: 21.2988 - val_loss: 584.7124 - val_mae: 21.1589\n",
      "Epoch 9/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 1s/step - loss: 649.9947 - mae: 21.6583 - val_loss: 583.2079 - val_mae: 21.1125\n",
      "Epoch 10/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 1s/step - loss: 588.1638 - mae: 20.6143 - val_loss: 591.1561 - val_mae: 21.3492\n",
      "Epoch 11/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 1s/step - loss: 630.0433 - mae: 21.6699 - val_loss: 575.7584 - val_mae: 20.8587\n",
      "Epoch 12/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 1s/step - loss: 613.8060 - mae: 21.4219 - val_loss: 583.3314 - val_mae: 21.1164\n",
      "Epoch 13/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 1s/step - loss: 622.4415 - mae: 21.3357 - val_loss: 597.4342 - val_mae: 21.5194\n",
      "Epoch 14/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 1s/step - loss: 624.0091 - mae: 21.4404 - val_loss: 570.3436 - val_mae: 20.6375\n",
      "Epoch 15/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 1s/step - loss: 614.1705 - mae: 20.6161 - val_loss: 579.0487 - val_mae: 20.9764\n",
      "Epoch 16/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 1s/step - loss: 605.7603 - mae: 21.3793 - val_loss: 585.6815 - val_mae: 21.1881\n",
      "Epoch 17/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 1s/step - loss: 627.2929 - mae: 21.3219 - val_loss: 585.2238 - val_mae: 21.1744\n",
      "Epoch 18/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 1s/step - loss: 629.3625 - mae: 21.6902 - val_loss: 571.4178 - val_mae: 20.6848\n",
      "Epoch 19/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 1s/step - loss: 590.0936 - mae: 20.6256 - val_loss: 601.7391 - val_mae: 21.6315\n",
      "Epoch 20/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 1s/step - loss: 619.9378 - mae: 21.2002 - val_loss: 586.0497 - val_mae: 21.1991\n",
      "Loss plot saved as: transfer_model_ResNet50\\transfer_model_ResNet50_loss_plot.jpg\n",
      "Metric plot saved as: transfer_model_ResNet50\\transfer_model_ResNet50_mae_plot.jpg\n"
     ]
    }
   ],
   "source": [
    "base_model = ResNet50(weights='imagenet', include_top=False)\n",
    "base_model.trainable = False  # Freeze the convolutional base\n",
    "\n",
    "# Define the model using the Sequential API\n",
    "transfer_model = Sequential([\n",
    "    base_model,\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dense(256, activation='relu'),  # Additional dense layer with relu activation\n",
    "    Dense(1, activation='linear')  # Output layer for regression\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "transfer_model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "history = transfer_model.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.2)\n",
    "end_time = time.time()\n",
    "\n",
    "modelname = 'transfer_model_ResNet50'\n",
    "calculate_and_log_training_time(modelname = modelname, start_time = start_time, end_time = end_time)\n",
    "save_model_and_config_and_metrics(model = transfer_model, history = history,  modelname = modelname)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
