{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_and_log_training_time(modelname, start_time, end_time):\n",
    "    training_duration = end_time - start_time\n",
    "    hours, rem = divmod(training_duration, 3600)\n",
    "    minutes, seconds = divmod(rem, 60)\n",
    "    \n",
    "    model_dir = modelname\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.makedirs(model_dir)\n",
    "    \n",
    "    filepath = os.path.join(model_dir, \"trainingtime.txt\")\n",
    "    with open(filepath, \"w\") as f:\n",
    "        f.write(f\"Training took {int(hours):02d}:{int(minutes):02d}:{seconds:02f} (hh:mm:ss).\")\n",
    "\n",
    "def save_model_config_with_optimizer(model, modelname):\n",
    "    model_dir = modelname\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.makedirs(model_dir)\n",
    "    \n",
    "    filepath = os.path.join(model_dir, \"model_config.txt\")\n",
    "    with open(filepath, 'w') as f:\n",
    "        for layer in model.layers:\n",
    "            f.write(f\"Layer: {layer.name}\\n\")\n",
    "            f.write(f\"Config: {layer.get_config()}\\n\\n\")\n",
    "        \n",
    "        optimizer_config = model.optimizer.get_config()\n",
    "        f.write(\"Optimizer Config:\\n\")\n",
    "        f.write(str(optimizer_config))\n",
    "\n",
    "def save_model(model, modelname):\n",
    "    model_dir = modelname\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.makedirs(model_dir)\n",
    "    \n",
    "    model_path = os.path.join(model_dir, modelname + \".keras\")\n",
    "    model.save(model_path)\n",
    "\n",
    "def save_performance_metrics(history, modelname):\n",
    "    model_dir = modelname\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.makedirs(model_dir)\n",
    "    \n",
    "    filepath = os.path.join(model_dir, 'performance_metrics.csv')\n",
    "    pd.DataFrame(history.history).to_csv(filepath)\n",
    "\n",
    "def plot_loss_and_metric(history, metric_name='accuracy', model_name='model'):\n",
    "    model_dir = model_name\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.makedirs(model_dir)\n",
    "    \n",
    "    # First plot: Training & validation loss\n",
    "    fig, ax = plt.subplots(figsize=(14, 6))\n",
    "    ax.plot(history.history['loss'], label='Train Loss')\n",
    "    ax.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    ax.set_title('Model Loss')\n",
    "    ax.set_ylabel('Loss')\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.legend(loc='upper right')\n",
    "    ax.grid(True)\n",
    "    loss_plot_filename = os.path.join(model_dir, f'{model_name}_loss_plot.jpg')\n",
    "    fig.savefig(loss_plot_filename)\n",
    "    print(f\"Loss plot saved as: {loss_plot_filename}\")\n",
    "    plt.close(fig)\n",
    "    \n",
    "    # Second plot: Training & validation metric\n",
    "    fig, ax = plt.subplots(figsize=(14, 6))\n",
    "    ax.plot(history.history[metric_name], label=f'Train {metric_name.capitalize()}')\n",
    "    ax.plot(history.history[f'val_{metric_name}'], label=f'Validation {metric_name.capitalize()}')\n",
    "    ax.set_title(f'Model {metric_name.capitalize()}')\n",
    "    ax.set_ylabel(metric_name.capitalize())\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.legend(loc='upper left')\n",
    "    ax.grid(True)\n",
    "    metric_plot_filename = os.path.join(model_dir, f'{model_name}_{metric_name}_plot.jpg')\n",
    "    fig.savefig(metric_plot_filename)\n",
    "    print(f\"Metric plot saved as: {metric_plot_filename}\")\n",
    "    plt.close(fig)\n",
    "\n",
    "def save_model_and_config_and_metrics(model, history, modelname = \"model\"):\n",
    "    save_model_config_with_optimizer(model, modelname = modelname)\n",
    "    #save_model(model, modelname = modelname)\n",
    "    save_performance_metrics(history, modelname = modelname)\n",
    "    plot_loss_and_metric(history, metric_name='mae', model_name= modelname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Greyscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"C:\\Users\\busjo\\Documents\\JADS\\Semester 2\\Deep Learning\\Project\\Part1_Processed_Grey.pkl\"\n",
    "# Open the pickle file in binary mode\n",
    "with open(path, 'rb') as file:\n",
    "    # Load the content of the file into a variable\n",
    "    grey_data = pickle.load(file)\n",
    "    \n",
    "sampled_grey_data = grey_data.sample(n=1500)\n",
    "\n",
    "X = np.stack(sampled_grey_data['Image'].values)  # Converts a column of arrays into a single numpy array\n",
    "X = X = X.reshape(X.shape[0], -1)\n",
    "y = sampled_grey_data['Age'].values\n",
    "#X = list(sampled_grey_data['Image'].values)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\busjo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 1s/step - loss: 9217.4170 - mae: 64.7921 - val_loss: 1759.6501 - val_mae: 35.3859\n",
      "Epoch 2/10\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 1s/step - loss: 1097.3640 - mae: 26.9959 - val_loss: 1565.7611 - val_mae: 33.4004\n",
      "Epoch 3/10\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 1s/step - loss: 1243.8094 - mae: 28.4231 - val_loss: 922.5847 - val_mae: 26.2375\n",
      "Epoch 4/10\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 993ms/step - loss: 741.1948 - mae: 22.2873 - val_loss: 743.2515 - val_mae: 23.2870\n",
      "Epoch 5/10\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 992ms/step - loss: 862.8376 - mae: 23.5564 - val_loss: 757.9734 - val_mae: 20.9726\n",
      "Epoch 6/10\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 1s/step - loss: 729.1170 - mae: 21.7215 - val_loss: 668.3164 - val_mae: 20.9323\n",
      "Epoch 7/10\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 1s/step - loss: 690.5264 - mae: 20.9721 - val_loss: 1132.1041 - val_mae: 28.8099\n",
      "Epoch 8/10\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 1s/step - loss: 863.8949 - mae: 23.3934 - val_loss: 652.4696 - val_mae: 21.0792\n",
      "Epoch 9/10\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 1s/step - loss: 682.2639 - mae: 20.8904 - val_loss: 637.4011 - val_mae: 19.8993\n",
      "Epoch 10/10\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 1000ms/step - loss: 614.7959 - mae: 19.9921 - val_loss: 785.2384 - val_mae: 20.3706\n",
      "Loss plot saved as: ann_grey\\ann_grey_loss_plot.jpg\n",
      "Metric plot saved as: ann_grey\\ann_grey_mae_plot.jpg\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([Dense(2048, activation = 'relu', input_shape=(65536,)),\n",
    "Dense(512, activation = 'relu' ),\n",
    "Dense(128, activation = 'relu' ),\n",
    "Dense(32, activation = 'relu' ),\n",
    "Dense(1)])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "\n",
    "start_time = time.time()\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
    "end_time = time.time()\n",
    "modelname = \"ann_grey\"\n",
    "calculate_and_log_training_time(modelname = modelname, start_time = start_time, end_time = end_time)\n",
    "save_model_and_config_and_metrics(model = model, history = history,  modelname = modelname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"C:\\Users\\busjo\\Documents\\JADS\\Semester 2\\Deep Learning\\Project\\Part1_Processed_RGB.pkl\"\n",
    "# Open the pickle file in binary mode\n",
    "with open(path, 'rb') as file:\n",
    "    # Load the content of the file into a variable\n",
    "    RGB_data = pickle.load(file)\n",
    "    \n",
    "sampled_RGB_data = RGB_data.sample(n=1000)\n",
    "\n",
    "X = np.stack(sampled_RGB_data['Image'].values)  # Converts a column of arrays into a single numpy array\n",
    "X = X = X.reshape(X.shape[0], -1)\n",
    "y = sampled_RGB_data['Age'].values\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\busjo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 5s/step - loss: 76285.6719 - mean_absolute_error: 130.6575 - val_loss: 952.3283 - val_mean_absolute_error: 22.0873\n",
      "Epoch 2/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 3s/step - loss: 971.5742 - mean_absolute_error: 24.6843 - val_loss: 745.7155 - val_mean_absolute_error: 23.9387\n",
      "Epoch 3/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 3s/step - loss: 1588.2229 - mean_absolute_error: 31.7824 - val_loss: 1008.0150 - val_mean_absolute_error: 23.2296\n",
      "Epoch 4/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 3s/step - loss: 656.2308 - mean_absolute_error: 20.6905 - val_loss: 797.0519 - val_mean_absolute_error: 24.6242\n",
      "Epoch 5/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 3s/step - loss: 872.7722 - mean_absolute_error: 23.0500 - val_loss: 2408.7200 - val_mean_absolute_error: 43.2442\n",
      "Epoch 6/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 3s/step - loss: 1319.5305 - mean_absolute_error: 29.1235 - val_loss: 552.5101 - val_mean_absolute_error: 19.9452\n",
      "Epoch 7/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 3s/step - loss: 639.1434 - mean_absolute_error: 19.9674 - val_loss: 543.4451 - val_mean_absolute_error: 19.2972\n",
      "Epoch 8/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 3s/step - loss: 714.0620 - mean_absolute_error: 21.3861 - val_loss: 542.2137 - val_mean_absolute_error: 19.2192\n",
      "Epoch 9/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 3s/step - loss: 698.5399 - mean_absolute_error: 20.6442 - val_loss: 574.7579 - val_mean_absolute_error: 20.8263\n",
      "Epoch 10/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 3s/step - loss: 568.6846 - mean_absolute_error: 19.1949 - val_loss: 578.4552 - val_mean_absolute_error: 20.8546\n",
      "Loss plot saved as: ann_rgb\\ann_rgb_loss_plot.jpg\n",
      "Metric plot saved as: ann_rgb\\ann_rgb_mae_plot.jpg\n"
     ]
    }
   ],
   "source": [
    "model2 = Sequential([Dense(2048, activation = 'relu', input_shape=(196608,)),\n",
    "Dense(512, activation = 'relu' ),\n",
    "Dense(128, activation = 'relu' ),\n",
    "Dense(32, activation = 'relu' ),\n",
    "Dense(1)])\n",
    "\n",
    "\n",
    "model2.compile(optimizer='adam', loss='mean_squared_error', metrics=['mean_absolute_error'])\n",
    "\n",
    "start_time = time.time()\n",
    "history2 = model2.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
    "end_time = time.time()\n",
    "\n",
    "modelname = \"ann_rgb\"\n",
    "calculate_and_log_training_time(modelname = modelname, start_time = start_time, end_time = end_time)\n",
    "save_model_and_config_and_metrics(model = model, history = history,  modelname = modelname)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
