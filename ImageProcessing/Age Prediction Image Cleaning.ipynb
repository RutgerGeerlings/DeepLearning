{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-04T19:56:45.933049Z",
     "start_time": "2024-04-04T19:56:20.332817Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Function to load and process a single image\n",
    "def load_image(image_path, color_mode='rgb', target_size=(256, 256)):\n",
    "    # Load the image\n",
    "    if color_mode == 'grayscale':\n",
    "        img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    else:  # Default to RGB\n",
    "        img = cv2.imread(image_path)\n",
    "    \n",
    "    # Load the face cascade and detect faces in the image\n",
    "    face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "    faces = face_cascade.detectMultiScale(img, 1.1, 4)\n",
    "\n",
    "    if len(faces) > 0:\n",
    "        # Assume the first detected face is the target\n",
    "        x, y, w, h = faces[0]\n",
    "        # Determine the center of the face\n",
    "        center_x, center_y = x + w // 2, y + h // 2\n",
    "        # Make the crop area square\n",
    "        size = max(w, h) // 2\n",
    "        # Calculate new x, y, w, h for the square crop\n",
    "        x_new = max(center_x - size, 0)\n",
    "        y_new = max(center_y - size, 0)\n",
    "        w_new = h_new = size * 2\n",
    "        # Crop the image to the new square bounds, making sure not to go out of the image's boundaries\n",
    "        crop_img = img[max(0, y_new):min(y_new + h_new, img.shape[0]), max(0, x_new):min(x_new + w_new, img.shape[1])]\n",
    "    else:\n",
    "        # If no face is detected, you can choose to return the original image or handle differently\n",
    "        crop_img = img\n",
    "\n",
    "    # Resize the cropped image (or the whole image if no face was detected) to the target size\n",
    "    resized_img = cv2.resize(crop_img, target_size)\n",
    "\n",
    "    return resized_img"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T19:56:53.252488Z",
     "start_time": "2024-04-04T19:56:53.231198Z"
    }
   },
   "id": "601032c2ede0360d"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Function to display an image using OpenCV\n",
    "def show_image_with_cv2(image, title='Image'):\n",
    "    cv2.imshow(title, image)\n",
    "    cv2.waitKey(0)  # Wait indefinitely for a key press\n",
    "    cv2.destroyAllWindows()  # Close the window when a key is pressed"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T19:56:53.814598Z",
     "start_time": "2024-04-04T19:56:53.787563Z"
    }
   },
   "id": "cd0bebfb538e18ee"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Function to process a folder of images\n",
    "def process_folder(folder_path, output_folder=None, color_mode='rgb', target_size=(256, 256)):\n",
    "    # Create the output folder if it doesn't exist\n",
    "    if output_folder and not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    \n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tif', '.tiff')):\n",
    "            image_path = os.path.join(folder_path, filename)\n",
    "            processed_img = load_image(image_path, color_mode=color_mode, target_size=target_size)\n",
    "            \n",
    "            if output_folder:\n",
    "                output_path = os.path.join(output_folder, filename)\n",
    "                # If the color mode is grayscale, we need to save it correctly\n",
    "                if color_mode == 'grayscale':\n",
    "                    cv2.imwrite(output_path, processed_img, grayscale=True)\n",
    "                else:\n",
    "                    cv2.imwrite(output_path, processed_img)\n",
    "            else:\n",
    "                # Show the image for verification, comment this out for production use\n",
    "                cv2.imshow('Processed Image', processed_img)\n",
    "                cv2.waitKey(0)\n",
    "                cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T19:56:54.384418Z",
     "start_time": "2024-04-04T19:56:54.326137Z"
    }
   },
   "id": "4ddde2c17f02aa5d"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: premature end of data segment\n",
      "Corrupt JPEG data: bad Huffman code\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    }
   ],
   "source": [
    "input_folder = '/Users/rutgergeerlings/PycharmProjects/Age Prediction/Images part 1'\n",
    "output_folder = '/Users/rutgergeerlings/PycharmProjects/Age Prediction/Part 1 processed rgb'\n",
    "process_folder(input_folder, output_folder, color_mode='rgb', target_size=(256, 256))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T19:47:31.712914Z",
     "start_time": "2024-04-04T19:40:25.966126Z"
    }
   },
   "id": "95e90c9c2403e2b8"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def load_and_normalize_image(image_path, color_mode='rgb'):\n",
    "    # Load the image\n",
    "    if color_mode == 'grayscale':\n",
    "        img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    else:  # Default to RGB\n",
    "        img = cv2.imread(image_path)\n",
    "    \n",
    "    # Normalize the image\n",
    "    img_normalized = img.astype('float32') / 255.0\n",
    "    \n",
    "    return img_normalized"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T19:56:57.777805Z",
     "start_time": "2024-04-04T19:56:57.588060Z"
    }
   },
   "id": "45f03cce03c57645"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def process_images(folder_path):\n",
    "    data_rgb = []\n",
    "    data_gray = []\n",
    "    \n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tif', '.tiff')):\n",
    "            parts = filename.split('_')\n",
    "            if len(parts) < 4:  # Check if filename format is correct\n",
    "                print(f\"Skipping file with unexpected format: {filename}\")\n",
    "                continue\n",
    "            \n",
    "            # Extract labels from filename\n",
    "            age = int(parts[0])\n",
    "            gender = int(parts[1])\n",
    "            race = int(parts[2])\n",
    "            \n",
    "            # Full path to the image file\n",
    "            image_path = os.path.join(folder_path, filename)\n",
    "            \n",
    "            # Load and normalize the image in both color modes\n",
    "            img_rgb = load_and_normalize_image(image_path, 'rgb')\n",
    "            img_gray = load_and_normalize_image(image_path, 'grayscale')\n",
    "            \n",
    "            # Append to the respective lists\n",
    "            data_rgb.append([age, gender, race, img_rgb])\n",
    "            data_gray.append([age, gender, race, img_gray])\n",
    "    \n",
    "    # Convert lists into pandas DataFrames\n",
    "    df_rgb = pd.DataFrame(data_rgb, columns=['Age', 'Gender', 'Race', 'Image'])\n",
    "    df_gray = pd.DataFrame(data_gray, columns=['Age', 'Gender', 'Race', 'Image'])\n",
    "    \n",
    "    return df_rgb, df_gray"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T19:56:58.309462Z",
     "start_time": "2024-04-04T19:56:58.271411Z"
    }
   },
   "id": "550bf637812d7bf3"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping file with unexpected format: 61_1_20170109142408075.jpg\n",
      "Skipping file with unexpected format: 61_3_20170109150557335.jpg\n"
     ]
    }
   ],
   "source": [
    "folder_path = '/Users/rutgergeerlings/PycharmProjects/Age Prediction/Part 1 processed rgb'\n",
    "df_rgb, df_gray = process_images(folder_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T19:57:16.952213Z",
     "start_time": "2024-04-04T19:57:04.405413Z"
    }
   },
   "id": "7671293949152bfb"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "   Age  Gender  Race                                              Image\n0   16       1     3  [[0.38431373, 0.37254903, 0.35686275, 0.341176...\n1   40       1     0  [[0.67058825, 0.67058825, 0.6666667, 0.6666667...\n2   71       1     0  [[0.6156863, 0.6392157, 0.7019608, 0.7607843, ...\n3   80       1     0  [[0.57254905, 0.57254905, 0.57254905, 0.572549...\n4   21       0     4  [[0.06666667, 0.05882353, 0.050980393, 0.05098...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Age</th>\n      <th>Gender</th>\n      <th>Race</th>\n      <th>Image</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>16</td>\n      <td>1</td>\n      <td>3</td>\n      <td>[[0.38431373, 0.37254903, 0.35686275, 0.341176...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>40</td>\n      <td>1</td>\n      <td>0</td>\n      <td>[[0.67058825, 0.67058825, 0.6666667, 0.6666667...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>71</td>\n      <td>1</td>\n      <td>0</td>\n      <td>[[0.6156863, 0.6392157, 0.7019608, 0.7607843, ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>80</td>\n      <td>1</td>\n      <td>0</td>\n      <td>[[0.57254905, 0.57254905, 0.57254905, 0.572549...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>21</td>\n      <td>0</td>\n      <td>4</td>\n      <td>[[0.06666667, 0.05882353, 0.050980393, 0.05098...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gray.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T19:59:25.267374Z",
     "start_time": "2024-04-04T19:59:25.090488Z"
    }
   },
   "id": "94dbd31bf690615"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "df_rgb.to_pickle('Part1_Processed_RGB.pkl')\n",
    "df_gray.to_pickle('Part1_Processed_Grey.pkl')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T20:01:47.391506Z",
     "start_time": "2024-04-04T20:01:27.137994Z"
    }
   },
   "id": "d49759a1cb6ad31d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "803e71d2a5d73c4b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-27e90844",
   "language": "python",
   "display_name": "PyCharm (DeepLearning)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}