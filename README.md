# Automated Age Verification - Code Execution Guide

## Dataset Overview

The UTKFace dataset is a large-scale face dataset with over 20,000 face images with annotations of age, gender, and ethnicity. The images vary in age from 0 to 116 years, providing a comprehensive range for studying facial features across different ages and demographic groups. The dataset is publicly available and has been widely utilized in the development of automated systems for age and demographic estimation.

Each image in the dataset is labeled with the subject's age, gender, and ethnicity, making it an ideal resource for training and testing machine learning models that perform demographic predictions. This rich set of annotations allows for the exploration of various facial recognition tasks, including the age estimation model used in this project to automate age verification processes at self-service checkouts.

For more details about the dataset and to access the data, visit [UTKFace Dataset](https://susanqq.github.io/UTKFace/).

## Repository Structure

- **ImageProcessing/Age Prediction Image Cleaning.ipynb**: This Pythonfile contains all necessary methods for cleaning and preprocessing the data. It must be run first to prepare the data for the model training process.
- **Models Directory**: Each subdirectory within the Models directory corresponds to a specific model configuration. The directory naming follows the pattern `Samplesize(RBG/Grey)(number of layers)(other tweaks)`, which describes the model setup. Each folder contains the resulted output of that specific model.
  - **Example**: `1000RBG3Dropout` would be a directory for a model trained on 1,000 RGB images with 3 layers, including dropout functionality.

## Running the Code

### Step 1: Data Cleaning and Preprocessing

1. Navigate to the `Age Prediction Image Cleaning.ipynb` file via the 'ImageProcessing' folder.
2. Run to perform data cleaning and preprocessing. Ensure the output data is correctly formatted and stored for subsequent training.

### Step 2: Model Training

1. All the model implementations are grouped into larger groups like how 'CNN_model_gray.ipynb' contains all the CNN models with greyscale.
2. Change the path of the input data to a local repository, the data was not able to be uploaded to Git due to size constraints.
3. Run the IPythonNoteBook file to train the model. Pay attention to the console output logs and file outputs that provide insights into the training process and performance.

### Step 3: Model Evaluation

- After training, review the outputs generated by the model training script. These include performance metrics and visualizations to assess the effectiveness of the model in its task.

## Additional Note

- For a detailed explanation of each model's configuration and specific tweaks, refer to the comments and documentation within each file in the model directories.
