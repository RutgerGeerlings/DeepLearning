{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-07T10:25:30.051784Z",
     "start_time": "2024-05-07T10:25:21.946101Z"
    }
   },
   "source": [
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.regularizers import l2\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "def calculate_and_log_training_time(modelname, start_time, end_time):\n",
    "    training_duration = end_time - start_time\n",
    "    hours, rem = divmod(training_duration, 3600)\n",
    "    minutes, seconds = divmod(rem, 60)\n",
    "    \n",
    "    model_dir = modelname\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.makedirs(model_dir)\n",
    "    \n",
    "    filepath = os.path.join(model_dir, \"trainingtime.txt\")\n",
    "    with open(filepath, \"w\") as f:\n",
    "        f.write(f\"Training took {int(hours):02d}:{int(minutes):02d}:{seconds:02f} (hh:mm:ss).\")\n",
    "\n",
    "def save_model_config_with_optimizer(model, modelname):\n",
    "    model_dir = modelname\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.makedirs(model_dir)\n",
    "    \n",
    "    filepath = os.path.join(model_dir, \"model_config.txt\")\n",
    "    with open(filepath, 'w') as f:\n",
    "        for layer in model.layers:\n",
    "            f.write(f\"Layer: {layer.name}\\n\")\n",
    "            f.write(f\"Config: {layer.get_config()}\\n\\n\")\n",
    "        \n",
    "        optimizer_config = model.optimizer.get_config()\n",
    "        f.write(\"Optimizer Config:\\n\")\n",
    "        f.write(str(optimizer_config))\n",
    "\n",
    "def save_model(model, modelname):\n",
    "    model_dir = modelname\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.makedirs(model_dir)\n",
    "    \n",
    "    model_path = os.path.join(model_dir, modelname + \".keras\")\n",
    "    model.save(model_path)\n",
    "\n",
    "def save_performance_metrics(history, modelname):\n",
    "    model_dir = modelname\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.makedirs(model_dir)\n",
    "    \n",
    "    filepath = os.path.join(model_dir, 'performance_metrics.csv')\n",
    "    pd.DataFrame(history.history).to_csv(filepath)\n",
    "    print(\"Performance metrics saved.\")\n",
    "\n",
    "\n",
    "def plot_loss_and_metrics(history, metrics=['accuracy'], model_name='model'):\n",
    "    model_dir = model_name\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.makedirs(model_dir)\n",
    "    \n",
    "    # Plot Training & Validation Loss\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    plt.plot(history.history['loss'], label='Train Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Model Loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.grid(True)\n",
    "    plt.savefig(os.path.join(model_dir, f'{model_name}_loss_plot.jpg'))\n",
    "    plt.close()\n",
    "\n",
    "    # Plot each metric\n",
    "    for metric in metrics:\n",
    "        plt.figure(figsize=(14, 6))\n",
    "        plt.plot(history.history[metric], label=f'Train {metric.capitalize()}')\n",
    "        plt.plot(history.history[f'val_{metric}'], label=f'Validation {metric.capitalize()}')\n",
    "        plt.title(f'Model {metric.capitalize()}')\n",
    "        plt.ylabel(metric.capitalize())\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.legend(loc='upper left')\n",
    "        plt.grid(True)\n",
    "        plt.savefig(os.path.join(model_dir, f'{model_name}_{metric}_plot.jpg'))\n",
    "        plt.close()\n",
    "        print(f\"Plot for {metric} saved.\")\n",
    "\n",
    "def save_model_and_config_and_metrics(model, history, modelname = \"model\", metrics=['accuracy']):\n",
    "    save_model_config_with_optimizer(model, modelname = modelname)\n",
    "    save_model(model, modelname = modelname)\n",
    "    save_performance_metrics(history, modelname = modelname)\n",
    "    plot_loss_and_metrics(history, metrics=metrics, model_name=modelname)\n",
    "    print(\"All model components and metrics have been saved.\")"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-07T10:25:39.560001Z",
     "start_time": "2024-05-07T10:25:30.053739Z"
    }
   },
   "cell_type": "code",
   "source": [
    "path = \"C:/Users/marij/Documents/Universiteit_local/Master_Year1/DeepLearning/Part1_Processed_RGB.pkl\"\n",
    "# Open the pickle file in binary mode\n",
    "with open(path, 'rb') as file:\n",
    "    # Load the content of the file into a variable\n",
    "    RGB_data = pickle.load(file)"
   ],
   "id": "901ee4fbe03d64bf",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-07T10:45:08.923609Z",
     "start_time": "2024-05-07T10:44:45.940591Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sampled_RGB_data = RGB_data.sample(n=4000, random_state = 2001)\n",
    "# Assuming your DataFrame is named sampled_RGB_data\n",
    "one_hot_encoded_races = pd.get_dummies(sampled_RGB_data['Race'], prefix='Race')\n",
    "# Concatenate the original DataFrame with the new one-hot encoded columns\n",
    "sampled_RGB_data = pd.concat([sampled_RGB_data, one_hot_encoded_races], axis=1)\n",
    "y = sampled_RGB_data[['Race_0', 'Race_1', 'Race_2',\n",
    "       'Race_3', 'Race_4']].values\n",
    "X = sampled_RGB_data['Image'].values\n",
    "X = np.stack(X)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ],
   "id": "c4c9fcc17e491ec9",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Model Race",
   "id": "8af99ca31b0a03f0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-07T11:12:55.468134Z",
     "start_time": "2024-05-07T10:45:08.960363Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define the number of unique races\n",
    "num_classes = len(sampled_RGB_data[\"Race\"].unique())\n",
    "\n",
    "# Define the model for binary classification (gender prediction)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.Input(shape=(256, 256, 3)),  # Define the input shape here\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_regularizer=l2(0.001)),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Dropout(0.25),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_regularizer=l2(0.001)),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Dropout(0.25),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_regularizer=l2(0.001)),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Dropout(0.25),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(num_classes, activation='softmax')  # Change activation to 'softmax'\n",
    "])\n",
    "\n",
    "# Compile the model with categorical crossentropy loss and a suitable optimizer\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# Capture start time\n",
    "start_time = time.time()\n",
    "# fit the model\n",
    "history = model.fit(X, y, epochs=12, validation_split=0.2)\n",
    "# Capture end time and calculate duration\n",
    "end_time = time.time()\n",
    "modelname =\"RaceAllRBGCNN3convdropoutregu\"\n",
    "calculate_and_log_training_time(modelname = modelname, start_time = start_time, end_time = end_time)\n",
    "save_model_and_config_and_metrics(model = model, history = history,  modelname = modelname)"
   ],
   "id": "186b72c53072d825",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "\u001B[1m100/100\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m203s\u001B[0m 2s/step - accuracy: 0.4942 - loss: 2.6874 - val_accuracy: 0.5050 - val_loss: 1.6383\n",
      "Epoch 2/12\n",
      "\u001B[1m100/100\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m125s\u001B[0m 1s/step - accuracy: 0.5306 - loss: 1.3718 - val_accuracy: 0.5050 - val_loss: 1.5156\n",
      "Epoch 3/12\n",
      "\u001B[1m100/100\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m122s\u001B[0m 1s/step - accuracy: 0.5393 - loss: 1.3129 - val_accuracy: 0.5100 - val_loss: 1.3217\n",
      "Epoch 4/12\n",
      "\u001B[1m100/100\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m125s\u001B[0m 1s/step - accuracy: 0.5513 - loss: 1.2431 - val_accuracy: 0.5462 - val_loss: 1.2809\n",
      "Epoch 5/12\n",
      "\u001B[1m100/100\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m140s\u001B[0m 1s/step - accuracy: 0.5734 - loss: 1.2194 - val_accuracy: 0.5325 - val_loss: 1.3216\n",
      "Epoch 6/12\n",
      "\u001B[1m100/100\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m130s\u001B[0m 1s/step - accuracy: 0.5773 - loss: 1.1924 - val_accuracy: 0.5500 - val_loss: 1.1834\n",
      "Epoch 7/12\n",
      "\u001B[1m100/100\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m144s\u001B[0m 1s/step - accuracy: 0.5899 - loss: 1.1238 - val_accuracy: 0.5725 - val_loss: 1.2031\n",
      "Epoch 8/12\n",
      "\u001B[1m100/100\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m123s\u001B[0m 1s/step - accuracy: 0.6093 - loss: 1.1066 - val_accuracy: 0.5775 - val_loss: 1.1866\n",
      "Epoch 9/12\n",
      "\u001B[1m100/100\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m123s\u001B[0m 1s/step - accuracy: 0.5988 - loss: 1.0809 - val_accuracy: 0.5700 - val_loss: 1.2121\n",
      "Epoch 10/12\n",
      "\u001B[1m100/100\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m126s\u001B[0m 1s/step - accuracy: 0.6234 - loss: 1.0298 - val_accuracy: 0.5938 - val_loss: 1.1196\n",
      "Epoch 11/12\n",
      "\u001B[1m100/100\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m122s\u001B[0m 1s/step - accuracy: 0.6392 - loss: 0.9951 - val_accuracy: 0.5938 - val_loss: 1.1063\n",
      "Epoch 12/12\n",
      "\u001B[1m100/100\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m135s\u001B[0m 1s/step - accuracy: 0.6576 - loss: 0.9197 - val_accuracy: 0.5962 - val_loss: 1.0806\n",
      "Performance metrics saved.\n",
      "Plot for accuracy saved.\n",
      "All model components and metrics have been saved.\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-07T10:44:17.733443Z",
     "start_time": "2024-05-07T10:44:17.704348Z"
    }
   },
   "cell_type": "code",
   "source": "sampled_RGB_data.columns",
   "id": "886f02041e0ca32",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Age', 'Gender', 'Race', 'Image', 'Race_0', 'Race_1', 'Race_2',\n",
       "       'Race_3', 'Race_4'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Checking for bias",
   "id": "d657bdbceda7ffdb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Load your model\n",
    "model = tf.keras.models.load_model('RaceAllRBGCNN3convdropoutregu/RaceAllRBGCNN3convdropoutregu.keras')"
   ],
   "id": "fcb598b6d76e48cd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-07T12:02:54.688835Z",
     "start_time": "2024-05-07T12:02:37.144342Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sampled_RGB_data = RGB_data.sample(n=4000, random_state = 2001)\n",
    "# Assuming your DataFrame is named sampled_RGB_data\n",
    "one_hot_encoded_races = pd.get_dummies(sampled_RGB_data['Race'], prefix='Race')\n",
    "# Concatenate the original DataFrame with the new one-hot encoded columns\n",
    "sampled_RGB_data = pd.concat([sampled_RGB_data, one_hot_encoded_races], axis=1)\n",
    "y = sampled_RGB_data[['Race_0', 'Race_1', 'Race_2',\n",
    "       'Race_3', 'Race_4']].values\n",
    "X = sampled_RGB_data['Image'].values\n",
    "X = np.stack(X)"
   ],
   "id": "32a16938529a6bd2",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-07T12:03:43.687825Z",
     "start_time": "2024-05-07T12:02:54.702880Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Generate predictions\n",
    "predicted_race = model.predict(X)\n",
    "# Create a new column 'actual_Race' in the DataFrame\n",
    "sampled_RGB_data['actual_Race'] = np.argmax(predicted_race, axis=1)\n"
   ],
   "id": "90d982d565c7c15b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m41s\u001B[0m 261ms/step\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-07T12:03:43.795778Z",
     "start_time": "2024-05-07T12:03:43.698955Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define age bins and labels\n",
    "bins = list(range(0, 110 + 10, 11))  # This goes from 0 to 100, changing this range as needed.\n",
    "labels = [f'{i}-{i+9}' for i in range(0, 100, 10)]\n",
    "\n",
    "# Create a new column for age categories\n",
    "sampled_RGB_data['Age_Category'] = pd.cut(sampled_RGB_data['Age'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "# Display the new DataFrame to verify the categories\n",
    "print(sampled_RGB_data[['Age', 'Age_Category']].head())"
   ],
   "id": "74fa8f5507de68e2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Age Age_Category\n",
      "3614   80        70-79\n",
      "5198    1          0-9\n",
      "8301    5          0-9\n",
      "3966    2          0-9\n",
      "9565   49        40-49\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-07T12:03:43.826553Z",
     "start_time": "2024-05-07T12:03:43.799778Z"
    }
   },
   "cell_type": "code",
   "source": "sampled_RGB_data.columns",
   "id": "ac32b56241a5f757",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Age', 'Gender', 'Race', 'Image', 'Race_0', 'Race_1', 'Race_2',\n",
       "       'Race_3', 'Race_4', 'actual_Race', 'Age_Category'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-07T12:08:10.039147Z",
     "start_time": "2024-05-07T12:08:09.994638Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Calculate the match between 'Race' and 'actual_Race'\n",
    "sampled_RGB_data['Race_Match'] = sampled_RGB_data['Race'] == sampled_RGB_data['actual_Race']\n",
    "\n",
    "# Group by 'Age_Category' and calculate the percentage of matches\n",
    "match_percentage_by_age = sampled_RGB_data.groupby('Age_Category')['Race_Match'].mean() * 100\n",
    "\n",
    "# Print the result\n",
    "print(match_percentage_by_age)"
   ],
   "id": "c8ac4cdb51e6872c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age_Category\n",
      "0-9      62.946429\n",
      "10-19    71.899225\n",
      "20-29    67.542504\n",
      "30-39    73.684211\n",
      "40-49    77.837838\n",
      "50-59    82.424242\n",
      "60-69    82.710280\n",
      "70-79    81.944444\n",
      "80-89    67.307692\n",
      "90-99    66.666667\n",
      "Name: Race_Match, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-39-b160066da629>:6: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  match_percentage_by_age = sampled_RGB_data.groupby('Age_Category')['Race_Match'].mean() * 100\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-07T12:11:34.203116Z",
     "start_time": "2024-05-07T12:11:34.175721Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Calculate the match between 'Race' and 'actual_Race'\n",
    "sampled_RGB_data['Race_Match'] = sampled_RGB_data['Race'] == sampled_RGB_data['actual_Race']\n",
    "\n",
    "# Group by 'Gender' and calculate the percentage of matches\n",
    "match_percentage_by_gender = sampled_RGB_data.groupby('Gender')['Race_Match'].mean() * 100\n",
    "\n",
    "# Print the result\n",
    "print(match_percentage_by_gender)"
   ],
   "id": "e9c8cf06aaa9f7b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender\n",
      "0    70.218579\n",
      "1    71.013825\n",
      "Name: Race_Match, dtype: float64\n"
     ]
    }
   ],
   "execution_count": 40
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
